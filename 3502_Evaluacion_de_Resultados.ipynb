{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce31a2ae-0f01-4fa6-a7e9-c946adbe19c3",
   "metadata": {
    "panel-layout": {
     "height": 437.933349609375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Evaluacion de Resultados\n",
    "\n",
    "\n",
    "En este NoteBook se  muestra para la evaliacion de los resulstados de una prediccion con un algoritmo de Ml(Machine Learning).\n",
    "\n",
    "## DATASET\n",
    "\n",
    "### Descripcion\n",
    "\n",
    "NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods. Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "### Ficheros de datos\n",
    "\n",
    "* KDDTrain+.ARFF: The full NSL-KDD train set with binary labels in ARFF format \n",
    "* KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format.\n",
    "* KDDTrain+_20Percent.ARFF: A 20% subset of the KDDTrain+.arff file\n",
    "* KDDTrain+_20Percent.TXT: A 20% subset of the KDDTrain+.txt file\n",
    "* KDDTest+.ARFF: The full NSL-KDD test set with binary labels in ARFF format\n",
    "* KDDTest+.TXT: The full NSL-KDD test set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTest-21.ARFF: A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21\n",
    "* KDDTest-21.TXT: A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2c726-da73-4f75-8fad-1dea495a7529",
   "metadata": {
    "panel-layout": {
     "height": 50.850006103515625,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4caa58d6-f8b0-4828-a61e-d5a7b2afecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose  import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3e2ff-a4fb-44dc-ae82-24bcdf8dfa88",
   "metadata": {
    "panel-layout": {
     "height": 60.616668701171875,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Funciones Auxiliares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7016ca1-8b33-4f54-89d8-a7a63de17d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"lectura del dataset NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes=[attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns=attributes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80437750-0468-4514-be29-98bf2e867945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construccion de una funcion que realize el particionado completo\n",
    "def train_val_test_split(df, rstate = 42 , shuffle = True, stratify = None):\n",
    "    strat=df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df,test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat=test_set[stratify] if stratify else None\n",
    "    val_set,test_set = train_test_split(\n",
    "        test_set,test_size=0.5,random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e02469-7091-489e-8bd3-593a961eb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion de construccion de un pipeline para los atributos numericos \n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('rbst_scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7b85f4-f621-4c64-9d65-493158d8f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranformador para codificar unicamente las columnas categoricas y devolver un dataframe\n",
    "class CustomOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._oh=OneHotEncoder(sparce_output=False)\n",
    "        self._columns = None\n",
    "    def fit(self, X, y = None):\n",
    "        X_cat=X.select_dtypes(include=[\"object\"])\n",
    "        self._columns=pd.get_dummies(X_cat).columns\n",
    "        self._oh.fit(X_cat)\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        X_copy=X.copy\n",
    "        X_cat=X_copy.select_dtypes(include =[\"object\"])\n",
    "        X_num=X_copy.select_dtypes(exclude =[\"object\"])\n",
    "        X_cat_oh=self._oh.transform(X_cat)\n",
    "        X_cat_oh=pd.DataFrame(X_cat_oh,\n",
    "                              columns=self._columns,\n",
    "                              index=X_copy.index)\n",
    "        X_copy.drop(list(X_cat),axis=1, inplace=True)\n",
    "        return X_copy.join(X_cat_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a198a88c-ca76-4692-bf71-5a6b674d7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador que prepara todo el dataset llamado pipelines\n",
    "#trasnformadores personalizados \n",
    "class DataFramePreparer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._full_pipeline = None\n",
    "        self._columns = None\n",
    "    def fit(self,X, y = None):\n",
    "        num_attribs=list(X.select_dtypes(exclude =[\"object\"]))\n",
    "        cat_attribs=list(X.select_dtypes(include =[\"object\"]))\n",
    "        self._full_pipeline=ColumnTransformer([\n",
    "            (\"num\", num_pipeline,num_attribs),\n",
    "            (\"cat\", CustomOneHotEncoder,cat_attribs)\n",
    "        ])\n",
    "        self._full_pipeline.fit(X)\n",
    "        self._columns=pd.get_dummies(X).columns\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy=X.copy()\n",
    "        X_prep=self._full_pipeline.transform(X_copy)\n",
    "        return pd.DataFrame(X_prep,columns=self._columns,index=X_copy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "961e4963-2ea8-4782-9424-37746277b871",
   "metadata": {
    "panel-layout": {
     "height": 330,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232.0</td>\n",
       "      <td>8153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>remote_job</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type     service flag  src_bytes  dst_bytes land  \\\n",
       "0       0.0           tcp    ftp_data   SF      491.0        0.0    0   \n",
       "1       0.0           udp       other   SF      146.0        0.0    0   \n",
       "2       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "3       0.0           tcp        http   SF      232.0     8153.0    0   \n",
       "4       0.0           tcp        http   SF      199.0      420.0    0   \n",
       "5       0.0           tcp     private  REJ        0.0        0.0    0   \n",
       "6       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "7       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "8       0.0           tcp  remote_job   S0        0.0        0.0    0   \n",
       "9       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0             0.0     0.0  0.0  ...                25.0   \n",
       "1             0.0     0.0  0.0  ...                 1.0   \n",
       "2             0.0     0.0  0.0  ...                26.0   \n",
       "3             0.0     0.0  0.0  ...               255.0   \n",
       "4             0.0     0.0  0.0  ...               255.0   \n",
       "5             0.0     0.0  0.0  ...                19.0   \n",
       "6             0.0     0.0  0.0  ...                 9.0   \n",
       "7             0.0     0.0  0.0  ...                15.0   \n",
       "8             0.0     0.0  0.0  ...                23.0   \n",
       "9             0.0     0.0  0.0  ...                13.0   \n",
       "\n",
       "  dst_host_same_srv_rate  dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                   0.17                    0.03                         0.17   \n",
       "1                   0.00                    0.60                         0.88   \n",
       "2                   0.10                    0.05                         0.00   \n",
       "3                   1.00                    0.00                         0.03   \n",
       "4                   1.00                    0.00                         0.00   \n",
       "5                   0.07                    0.07                         0.00   \n",
       "6                   0.04                    0.05                         0.00   \n",
       "7                   0.06                    0.07                         0.00   \n",
       "8                   0.09                    0.05                         0.00   \n",
       "9                   0.05                    0.06                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "5                         0.00                  0.00   \n",
       "6                         0.00                  1.00   \n",
       "7                         0.00                  1.00   \n",
       "8                         0.00                  1.00   \n",
       "9                         0.00                  1.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "5                      0.00                  1.00                      1.00   \n",
       "6                      1.00                  0.00                      0.00   \n",
       "7                      1.00                  0.00                      0.00   \n",
       "8                      1.00                  0.00                      0.00   \n",
       "9                      1.00                  0.00                      0.00   \n",
       "\n",
       "     class  \n",
       "0   normal  \n",
       "1   normal  \n",
       "2  anomaly  \n",
       "3   normal  \n",
       "4   normal  \n",
       "5  anomaly  \n",
       "6  anomaly  \n",
       "7  anomaly  \n",
       "8  anomaly  \n",
       "9  anomaly  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =load_kdd_dataset('datasets/NSL-KDD/KDDTrain+.arff')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3bccf-7abd-44fd-9fc6-8b9b88d5a28d",
   "metadata": {},
   "source": [
    "# Divicion del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "852abafb-9500-46ee-a11d-4ddcb8778a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divicion de dataset en los diferentes subconjuntos \n",
    "train_set,val_set,test_set=train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c236de-352c-4ef6-a521-cea9645102df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOngitud del Training Set 75583\n",
      "LOngitud del Validacion 25195\n",
      "LOngitud del test set 25195\n"
     ]
    }
   ],
   "source": [
    "print(\"LOngitud del Training Set\",len(train_set))\n",
    "print(\"LOngitud del Validacion\",len(val_set))\n",
    "print(\"LOngitud del test set\",len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc620bf-8b4c-4850-83da-b7d1657c1039",
   "metadata": {},
   "source": [
    "Para cada uno de los subconjuntos se separa las etiquetas de las caracteristicas de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebc32d7-67b0-41ee-bf4c-7f5a84a0afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset general\n",
    "X_df=df.drop(\"class\",axis=1)\n",
    "y_df=df[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f094f31a-4c25-4632-81f7-84f2b3d7614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset general de entrenamiento \n",
    "X_train=train_set.drop(\"class\",axis=1)\n",
    "y_train=train_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739a950c-a42f-458c-bca7-1715faeed2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conjunto de datos de validacion\n",
    "X_val=val_set.drop(\"class\",axis=1)\n",
    "y_val=val_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f574c5-e1a0-4d9c-9a56-47946685549d",
   "metadata": {},
   "source": [
    "# Preparacion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be03186-4196-47bf-88d7-3e756ecb2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciamos el transformaion personalizado\n",
    "data_preparer=DataFramePreparer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c187fd2-495e-44df-84c3-a44828120279",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Hacer el fit con el data set general para que adquiera todos los valores posibles \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_preparer\u001b[38;5;241m.\u001b[39mfit(X_df)\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mDataFramePreparer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m cat_attribs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mselect_dtypes(include \u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_pipeline\u001b[38;5;241m=\u001b[39mColumnTransformer([\n\u001b[1;32m     11\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_pipeline,num_attribs),\n\u001b[1;32m     12\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m, CustomOneHotEncoder,cat_attribs)\n\u001b[1;32m     13\u001b[0m ])\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_pipeline\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mget_dummies(X)\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:922\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    919\u001b[0m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_transform(X, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:976\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[0;32m--> 976\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_func_on_transformers(\n\u001b[1;32m    977\u001b[0m     X,\n\u001b[1;32m    978\u001b[0m     y,\n\u001b[1;32m    979\u001b[0m     _fit_transform_one,\n\u001b[1;32m    980\u001b[0m     column_as_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    981\u001b[0m     routed_params\u001b[38;5;241m=\u001b[39mrouted_params,\n\u001b[1;32m    982\u001b[0m )\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:876\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# func is _transform_one\u001b[39;00m\n\u001b[1;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m--> 876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m    877\u001b[0m                 X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    878\u001b[0m                 y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    879\u001b[0m                 weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[1;32m    880\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_args,\n\u001b[1;32m    881\u001b[0m                 params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[1;32m    882\u001b[0m             )\n\u001b[1;32m    883\u001b[0m         )\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(jobs)\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:91\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[38;5;241m=\u001b[39msafe)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:107\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m--> 107\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should provide an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn estimator instead of a class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    114\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[1;32m    118\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."
     ]
    }
   ],
   "source": [
    "#Hacer el fit con el data set general para que adquiera todos los valores posibles \n",
    "data_preparer.fit(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4776f9f-1bba-47c3-9b3e-67d156cf3fc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ColumnTransformer' object has no attribute 'transformers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#tranformar el dataset de entrenamieto \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train_prep\u001b[38;5;241m=\u001b[39mdata_preparer\u001b[38;5;241m.\u001b[39mtransform(X_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mDataFramePreparer.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     18\u001b[0m     X_copy\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 19\u001b[0m     X_prep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_pipeline\u001b[38;5;241m.\u001b[39mtransform(X_copy)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_prep,columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns,index\u001b[38;5;241m=\u001b[39mX_copy\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1051\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m   1048\u001b[0m column_names \u001b[38;5;241m=\u001b[39m _get_feature_names(X)\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_dataframe_and_transform_dataframe:\n\u001b[0;32m-> 1051\u001b[0m     named_transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_transformers_\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# check that all names seen in fit are in transform, unless\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;66;03m# they were dropped\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m     non_dropped_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1055\u001b[0m         ind\n\u001b[1;32m   1056\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1057\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m named_transformers \u001b[38;5;129;01mand\u001b[39;00m named_transformers[name] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1058\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:582\u001b[0m, in \u001b[0;36mColumnTransformer.named_transformers_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Access the fitted transformer by name.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03mRead-only attribute to access any transformer by given name.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03mKeys are transformer names and values are the fitted transformer\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03mobjects.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# Use Bunch object to improve autocomplete\u001b[39;00m\n\u001b[0;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bunch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{name: trans \u001b[38;5;28;01mfor\u001b[39;00m name, trans, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers_})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ColumnTransformer' object has no attribute 'transformers_'"
     ]
    }
   ],
   "source": [
    "#tranformar el dataset de entrenamieto \n",
    "X_train_prep=data_preparer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b83e21-772f-44df-b0de-83de1291c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35a21c-9202-469e-a4c9-4affe22221ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e053494-9c1e-4647-be83-45177b3ed338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranformamos el dataset de validacion\n",
    "X_val_prep=data_preparer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380bba3-5f10-439e-9a3b-2d15af003252",
   "metadata": {},
   "source": [
    "## Entrenamiento del Algoritmo de Regresion Logistica "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea78ebb-64fe-4a5a-96b0-0aa60812010f",
   "metadata": {},
   "source": [
    "El Instanciamiento de un algoritmo de Machine Learning(ML)utilizando Sklearn se realiza utilizando los metodos expuestos por la api de SKlearn, tal como se ha presentado de Notebooks anteriores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ba12244-0851-4e4d-9bf4-e6d131940945",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_prep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train_prep, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_prep' is not defined"
     ]
    }
   ],
   "source": [
    "#entrenar el algoritmo basado en regresion logistica \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "clf.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd0e3b-20b6-4673-81c0-ab9f5c4c86ab",
   "metadata": {},
   "source": [
    "## Prediccion de Nuevos ejemplos \n",
    "\n",
    "Realizar una prediccion con el metod generado anteriormente, tras el entrenamiento del algoritmo de Regresion LOgistica \n",
    "se utilizara el subconjuntio de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62320cf2-e027-4fa1-8d2d-34f4931eb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_val_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd79c9-42d7-4c1a-b955-c566ca00736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de confucion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28de1d-ac9f-4f11-9cd4-01b17a94b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_conficion_matrix\n",
    "plot_confucion_matrix(clf,X_val_prep,y_val,values_format='3g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a49e6-4ef2-4258-a6e5-4b94711ac73a",
   "metadata": {},
   "source": [
    "# Metricas derivadas de la matriz de confucion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243974b-9f3a-4e04-a971-911392b6ff8f",
   "metadata": {},
   "source": [
    "## Precicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64968a5-3660-41db-83a2-0158466b4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(\"precision\",precision_score(y_val,y_prep,pos_label='anomaly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3410266-21a8-4f15-9654-a373817cc2eb",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990b3a5-7ea0-4d63-9e50-26aa67e0a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall\",recall_score(y_val,y_prep,pos_label='anomaly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b499061-ad46-44d1-8e3b-99c0885dacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Curbas ROC y PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad64ee0-5a4f-4e84-a94f-67394565384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(clf,X_val_prep,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98aa389-0b19-4491-a503-c32d66b6f68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "ce31a2ae-0f01-4fa6-a7e9-c946adbe19c3",
   "71c2c726-da73-4f75-8fad-1dea495a7529",
   "dda3e2ff-a4fb-44dc-ae82-24bcdf8dfa88",
   "961e4963-2ea8-4782-9424-37746277b871"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
